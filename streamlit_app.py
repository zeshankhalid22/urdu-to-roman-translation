import streamlit as st
import torch
import torch.nn as nn
import json
import re
import unicodedata
from PIL import Image
import base64

# Page configuration with custom theme
st.set_page_config(
    page_title="Urdu to Roman Urdu Translator",
    page_icon="ğŸ”¤",
    layout="wide",
    initial_sidebar_state="collapsed",
)

# Custom CSS for styling
def add_custom_css():
    st.markdown("""
    <style>
        /* Main page styling */
        .main {
            background-color: #f7f7f7;
            padding: 20px;
        }
        
        /* Header styling */
        .header-container {
            background-color: #f0f2f6;
            padding: 1.5rem;
            border-radius: 10px;
            margin-bottom: 1.5rem;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
            text-align: center;
        }
        
        /* Text areas */
        .stTextArea textarea {
            border-radius: 8px;
            border: 1px solid #e0e0e0;
            padding: 10px;
            font-size: 16px;
            font-family: 'Jameel Noori Nastaleeq', Arial, sans-serif;
        }
        
        /* Translation result container */
        .result-container {
            background-color: #f0f2f6;
            padding: 1.5rem;
            border-radius: 10px;
            margin-top: 1rem;
            border-left: 5px solid #4CAF50;
        }
        
        /* Button styling */
        .stButton button {
            border-radius: 8px;
            padding: 0.5rem 1rem;
            font-weight: 500;
            transition: all 0.2s ease;
            width: 100%;
            margin-bottom: 0.5rem;
        }
        .stButton button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        }
        
        /* Example buttons with custom colors */
        .example-btn-1 button {
            background-color: #5c6bc0;
            color: white;
        }
        .example-btn-2 button {
            background-color: #26a69a;
            color: white;
        }
        .example-btn-3 button {
            background-color: #ec407a;
            color: white;
        }
        .example-btn-4 button {
            background-color: #ffa726;
            color: white;
        }
        .example-btn-5 button {
            background-color: #7e57c2;
            color: white;
        }
        
        /* Footer styling */
        .footer {
            text-align: center;
            margin-top: 2rem;
            padding-top: 1rem;
            border-top: 1px solid #e0e0e0;
            font-size: 0.8rem;
            color: #666;
        }
        
        /* Card layout for examples */
        .card-container {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(300px, 1fr));
            gap: 1rem;
            margin: 1rem 0;
        }
        
        .card {
            padding: 1rem;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
            background-color: white;
            transition: transform 0.2s;
            height: 100%;
        }
        
        .card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        }
        
        /* Loading animation */
        .loading-spinner {
            text-align: center;
            padding: 2rem;
        }
        
        /* Tab styling */
        .stTabs [data-baseweb="tab-list"] {
            gap: 10px;
        }
        
        .stTabs [data-baseweb="tab"] {
            border-radius: 4px 4px 0px 0px;
            padding: 10px 20px;
            background-color: #f0f2f6;
        }
        
        .stTabs [aria-selected="true"] {
            background-color: #4CAF50 !important;
            color: white !important;
        }
        
        /* Hide Streamlit branding */
        #MainMenu {visibility: hidden;}
        footer {visibility: hidden;}
    </style>
    """, unsafe_allow_html=True)

add_custom_css()

# Header with logo
st.markdown("""
<div class="header-container">
    <h1>Urdu to Roman Urdu Translator</h1>
    <p>Neural Machine Translation for Urdu Poetry and Text</p>
</div>
""", unsafe_allow_html=True)

# Model definitions (unchanged)
class Encoder(nn.Module):
    def __init__(self, input_size, embed_size, hidden_size, num_layers=1, dropout=0.1):
        super(Encoder, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers

        self.embedding = nn.Embedding(input_size, embed_size)
        self.lstm = nn.LSTM(
            embed_size,
            hidden_size,
            num_layers=num_layers,
            bidirectional=True,
            dropout=dropout if num_layers > 1 else 0,
            batch_first=True
        )
        self.fc_hidden = nn.Linear(hidden_size * 2, hidden_size)
        self.fc_cell = nn.Linear(hidden_size * 2, hidden_size)
        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        embedded = self.dropout(self.embedding(x))
        outputs, (hidden, cell) = self.lstm(embedded)
        
        hidden_forward = hidden[0:self.num_layers]
        hidden_backward = hidden[self.num_layers:]
        cell_forward = cell[0:self.num_layers]
        cell_backward = cell[self.num_layers:]

        last_hidden_forward = hidden_forward[-1]
        last_hidden_backward = hidden_backward[-1]
        last_cell_forward = cell_forward[-1]
        last_cell_backward = cell_backward[-1]

        last_hidden = torch.cat([last_hidden_forward, last_hidden_backward], dim=1)
        last_cell = torch.cat([last_cell_forward, last_cell_backward], dim=1)

        dec_hidden = self.fc_hidden(last_hidden)
        dec_cell = self.fc_cell(last_cell)

        return outputs, dec_hidden, dec_cell

class Attention(nn.Module):
    def __init__(self, enc_hidden_dim, dec_hidden_dim):
        super(Attention, self).__init__()
        self.attn = nn.Linear((enc_hidden_dim * 2) + dec_hidden_dim, dec_hidden_dim)
        self.v = nn.Linear(dec_hidden_dim, 1, bias=False)

    def forward(self, hidden, encoder_outputs):
        src_len = encoder_outputs.shape[1]
        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)
        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))
        attention = self.v(energy).squeeze(2)
        return nn.functional.softmax(attention, dim=1)

class AttentionDecoder(nn.Module):
    def __init__(self, output_size, embed_size, enc_hidden_size, dec_hidden_size, 
                 num_layers=2, dropout=0.1):
        super(AttentionDecoder, self).__init__()
        self.output_size = output_size
        self.hidden_size = dec_hidden_size
        self.num_layers = num_layers

        self.embedding = nn.Embedding(output_size, embed_size)
        self.attention = Attention(enc_hidden_size, dec_hidden_size)
        
        self.lstm = nn.LSTM(
            embed_size + (enc_hidden_size * 2),
            dec_hidden_size,
            num_layers=num_layers,
            dropout=dropout if num_layers > 1 else 0,
            batch_first=True
        )
        
        self.fc_out = nn.Linear(dec_hidden_size + embed_size + (enc_hidden_size * 2), output_size)
        self.dropout = nn.Dropout(dropout)

    def forward(self, input, hidden, cell, encoder_outputs):
        # Handle input dimensions
        if input.dim() > 1:
            input = input.squeeze(-1)
        
        embedded = self.dropout(self.embedding(input))
        embedded = embedded.unsqueeze(1)
        
        top_hidden = hidden[-1]
        attn_weights = self.attention(top_hidden, encoder_outputs)
        
        context = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs)
        
        rnn_input = torch.cat((embedded, context), dim=2)
        
        output, (hidden, cell) = self.lstm(rnn_input, (hidden, cell))
        
        embedded = embedded.squeeze(1)
        output = output.squeeze(1)
        context = context.squeeze(1)
        
        prediction = self.fc_out(torch.cat((output, embedded, context), dim=1))
        
        return prediction, hidden, cell, attn_weights

class Seq2Seq(nn.Module):
    def __init__(self, encoder, decoder, device):
        super(Seq2Seq, self).__init__()
        self.encoder = encoder
        self.decoder = decoder
        self.device = device

    def forward(self, src, tgt, teacher_forcing_ratio=0.5):
        # Not used for inference
        pass

    def translate(self, src, max_len=350):
        """Simple greedy decoding"""
        batch_size = src.shape[0]
        sos_token = 0  # Start token index
        eos_token = 2  # End token index
        
        # Initialize output tensor
        outputs = torch.zeros(batch_size, max_len, dtype=torch.long, device=src.device)
        outputs[:, 0] = sos_token
        
        # Encode the source
        encoder_outputs, hidden, cell = self.encoder(src)
        
        # Prepare decoder hidden state
        hidden = hidden.unsqueeze(0).repeat(self.decoder.num_layers, 1, 1)
        cell = cell.unsqueeze(0).repeat(self.decoder.num_layers, 1, 1)
        
        # Start with SOS token
        current_token = torch.tensor([sos_token], device=src.device)
        
        # Decode one token at a time
        for t in range(1, max_len):
            # Get output from decoder
            output, hidden, cell, _ = self.decoder(current_token, hidden, cell, encoder_outputs)
            
            # Get most likely next token
            current_token = output.argmax(1)
            
            # Save to output tensor
            outputs[:, t] = current_token
            
            # Stop if EOS token
            if current_token.item() == eos_token:
                break
        
        return outputs

# Helper function to load model (unchanged)
@st.cache_resource
def load_model():
    try:
        # Load vocabularies
        with open("static/urdu_vocab.json", "r", encoding="utf-8") as f:
            urdu_vocab_map = json.load(f)
        
        with open("static/roman_vocab.json", "r", encoding="utf-8") as f:
            roman_vocab_map = json.load(f)
            
        with open("static/urdu_merges.json", "r", encoding="utf-8") as f:
            urdu_merges = json.load(f)
        
        # Model parameters
        input_size = len(urdu_vocab_map) + 1
        output_size = len(roman_vocab_map) + 1
        embed_size = 128
        hidden_size = 128
        enc_layers = 1
        dec_layers = 2
        dropout = 0.1
        device = torch.device('cpu')
        
        # Create model
        encoder = Encoder(input_size, embed_size, hidden_size, enc_layers, dropout)
        decoder = AttentionDecoder(output_size, embed_size, hidden_size, hidden_size, dec_layers, dropout)
        model = Seq2Seq(encoder, decoder, device)
        
        # Load state dict
        model_data = torch.load("static/model.pt", map_location=device)
        
        # Handle different saved formats
        if isinstance(model_data, dict) and 'model_state_dict' in model_data:
            model.load_state_dict(model_data['model_state_dict'])
        elif isinstance(model_data, dict):
            model.load_state_dict(model_data)
        else:
            # If model is already a model object, not a state dict
            model = model_data
            
        model.eval()
        
        return model, urdu_vocab_map, roman_vocab_map, urdu_merges
    except Exception as e:
        st.error(f"Error loading model: {str(e)}")
        import traceback
        st.error(traceback.format_exc())
        return None, None, None, None

# Helper functions (unchanged)
def merge_pair(tokens, pair, new_token):
    result = []
    i = 0
    while i < len(tokens):
        if i < len(tokens)-1 and (tokens[i], tokens[i+1]) == pair:
            result.append(new_token)
            i += 2
        else:
            result.append(tokens[i])
            i += 1
    return result

def tokenize_urdu(text, urdu_merges, urdu_vocab_map):
    # Clean text
    text = unicodedata.normalize('NFC', text)
    text = re.sub(r'[^\u0600-\u06FF\u0750-\u077F\u08A0-\u08FF\u0900-\u097F\s\n]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    
    # Tokenize with word boundaries
    tokens = []
    for word in text.split():
        tokens.append('â–')  # Word boundary marker
        for char in word:
            tokens.append(char)
    
    tokens.append('<eos>')
    
    # Apply merges
    for pair, new_token in urdu_merges:
        tokens = merge_pair(tokens, tuple(pair), new_token)
    
    # Convert to indices
    indices = [urdu_vocab_map.get(token, len(urdu_vocab_map)) for token in tokens]
    
    return tokens, indices

def translate_text(text, model, urdu_merges, urdu_vocab_map, roman_vocab_map):
    try:
        # Tokenize
        _, indices = tokenize_urdu(text, urdu_merges, urdu_vocab_map)
        
        # Convert to tensor
        src_tensor = torch.tensor([indices], dtype=torch.long)
        
        # Translate
        with torch.no_grad():
            output = model.translate(src_tensor)
            
        # Convert output indices to text
        translation = []
        for idx in output[0, 1:].cpu().numpy():  # Skip <sos>
            if idx >= len(roman_vocab_map) or idx == 0:  # Skip padding and unknown
                continue
            token = next((k for k, v in roman_vocab_map.items() if v == idx), None)
            if token == '<eos>':
                break
            if token:
                translation.append(token)
        
        # Join tokens
        roman_text = ''.join(translation).replace('_', ' ')
        return roman_text
    except Exception as e:
        import traceback
        return f"Translation error: {str(e)}"

# Example poetry
example_1 = """Ø¯Ù„ Ù†Û’ ÙˆÙØ§ Ú©Û’ Ù†Ø§Ù… Ù¾Ø± Ú©Ø§Ø± ÙˆÙØ§ Ù†ÛÛŒÚº Ú©ÛŒØ§ Ø®ÙˆØ¯ Ú©Ùˆ ÛÙ„Ø§Ú© Ú©Ø± Ù„ÛŒØ§ Ø®ÙˆØ¯ Ú©Ùˆ ÙØ¯Ø§ Ù†ÛÛŒÚº Ú©ÛŒØ§ Ø®ÛŒØ±Û Ø³Ø±Ø§Ù† Ø´ÙˆÙ‚ Ú©Ø§ Ú©ÙˆØ¦ÛŒ Ù†ÛÛŒÚº ÛÛ’ Ø¬Ù†Ø¨Û Ø¯Ø§Ø± Ø´ÛØ± Ù…ÛŒÚº Ø§Ø³ Ú¯Ø±ÙˆÛ Ù†Û’ Ú©Ø³ Ú©Ùˆ Ø®ÙØ§ Ù†ÛÛŒÚº Ú©ÛŒØ§ Ø¬Ùˆ Ø¨Ú¾ÛŒ ÛÙˆ ØªÙ… Ù¾Û Ù…Ø¹ØªØ±Ø¶ Ø§Ø³ Ú©Ùˆ ÛŒÛÛŒ Ø¬ÙˆØ§Ø¨ Ø¯Ùˆ Ø¢Ù¾ Ø¨ÛØª Ø´Ø±ÛŒÙ ÛÛŒÚº Ø¢Ù¾ Ù†Û’ Ú©ÛŒØ§ Ù†ÛÛŒÚº Ú©ÛŒØ§ Ù†Ø³Ø¨Øª Ø¹Ù„Ù… ÛÛ’ Ø¨ÛØª Ø­Ø§Ú©Ù… ÙˆÙ‚Øª Ú©Ùˆ Ø¹Ø²ÛŒØ² Ø§Ø³ Ù†Û’ ØªÙˆ Ú©Ø§Ø± Ø¬ÛÙ„ Ø¨Ú¾ÛŒ Ø¨Û’ Ø¹Ù„Ù…Ø§ Ù†ÛÛŒÚº Ú©ÛŒØ§ Ø¬Ø³ Ú©Ùˆ Ø¨Ú¾ÛŒ Ø´ÛŒØ® Ùˆ Ø´Ø§Û Ù†Û’ Ø­Ú©Ù… Ø®Ø¯Ø§ Ø¯ÛŒØ§ Ù‚Ø±Ø§Ø± ÛÙ… Ù†Û’ Ù†ÛÛŒÚº Ú©ÛŒØ§ ÙˆÛ Ú©Ø§Ù… ÛØ§Úº Ø¨Û Ø®Ø¯Ø§ Ù†ÛÛŒÚº Ú©ÛŒØ§"""

example_2 = """Ø¯ÛŒØ§ Ø³Ø§ Ø¯Ù„ Ú©Û’ Ø®Ø±Ø§Ø¨Û’ Ù…ÛŒÚº Ø¬Ù„ Ø±ÛØ§ ÛÛ’ Ù…ÛŒØ§Úº Ø¯ÛŒÛ’ Ú©Û’ Ú¯Ø±Ø¯ Ú©ÙˆØ¦ÛŒ Ø¹Ú©Ø³ Ú†Ù„ Ø±ÛØ§ ÛÛ’ Ù…ÛŒØ§Úº ÛŒÛ Ø±ÙˆØ­ Ø±Ù‚Øµ Ú†Ø±Ø§ØºØ§Úº ÛÛ’ Ø§Ù¾Ù†Û’ Ø­Ù„Ù‚Û’ Ù…ÛŒÚº ÛŒÛ Ø¬Ø³Ù… Ø³Ø§ÛŒÛ ÛÛ’ Ø§ÙˆØ± Ø³Ø§ÛŒÛ ÚˆÚ¾Ù„ Ø±ÛØ§ Ù…ÛŒØ§Úº ÛŒÛ Ø¢Ù†Ú©Ú¾ Ù¾Ø±Ø¯Û ÛÛ’ Ø§Ú© Ú¯Ø±Ø¯Ø´ ØªØ­ÛŒØ± Ú©Ø§ ÛŒÛ Ø¯Ù„ Ù†ÛÛŒÚº ÛÛ’ Ø¨Ú¯ÙˆÙ„Û Ø§Ú†Ú¾Ù„ Ø±ÛØ§ ÛÛ’ Ù…ÛŒØ§Úº Ú©Ø¨Ú¾ÛŒ Ú©Ø³ÛŒ Ú©Ø§ Ú¯Ø²Ø±Ù†Ø§ Ú©Ø¨Ú¾ÛŒ Ù¹Ú¾ÛØ± Ø¬Ø§Ù†Ø§ Ù…Ø±Û’ Ø³Ú©ÙˆØª Ù…ÛŒÚº Ú©ÛŒØ§ Ú©ÛŒØ§ Ø®Ù„Ù„ Ø±ÛØ§ ÛÛ’ Ù…ÛŒØ§Úº Ú©Ø³ÛŒ Ú©ÛŒ Ø±Ø§Û Ù…ÛŒÚº Ø§ÙÙ„Ø§Ú© Ø²ÛŒØ± Ù¾Ø§ ÛÙˆØªÛ’ ÛŒÛØ§Úº ØªÙˆ Ù¾Ø§Ø¤Úº Ø³Û’ ØµØ­Ø±Ø§ Ù†Ú©Ù„ Ø±ÛØ§ ÛÛ’ Ù…ÛŒØ§Úº ÛØ¬ÙˆÙ… Ø´ÙˆØ® Ù…ÛŒÚº ÛŒÛ Ø¯Ù„ ÛÛŒ Ø¨Û’ ØºØ±Ø¶ Ù†Ú©Ù„Ø§ Ú†Ù„Ùˆ Ú©ÙˆØ¦ÛŒ ØªÙˆ Ø­Ø±ÛŒÙØ§Ù†Û Ú†Ù„ Ø±ÛØ§ ÛÛ’ Ù…ÛŒØ§Úº ØªØ¬Ú¾Û’ Ø§Ø¨Ú¾ÛŒ Ø³Û’ Ù¾Ú‘ÛŒ ÛÛ’ Ú©Û ÙÛŒØµÙ„Û ÛÙˆ Ø¬Ø§Ø¦Û’ Ù†Û Ø¬Ø§Ù†Û’ Ú©Ø¨ Ø³Û’ ÛŒÛØ§Úº ÙˆÙ‚Øª Ù¹Ù„ Ø±ÛØ§ ÛÛ’ Ù…ÛŒØ§Úº Ø·Ø¨ÛŒØ¹ØªÙˆÚº ÛÛŒ Ú©Û’ Ù…Ù„Ù†Û’ Ø³Û’ ØªÚ¾Ø§ Ù…Ø²Û Ø¨Ø§Ù‚ÛŒ Ø³Ùˆ ÙˆÛ Ù…Ø²Û Ø¨Ú¾ÛŒ Ú©ÛØ§Úº Ø¢Ø¬ Ú©Ù„ Ø±ÛØ§ ÛÛ’ Ù…ÛŒØ§Úº ØºÙ…ÙˆÚº Ú©ÛŒ ÙØµÙ„ Ù…ÛŒÚº Ø¬Ø³ ØºÙ… Ú©Ùˆ Ø±Ø§Ø¦ÛŒÚ¯Ø§Úº Ø³Ù…Ø¬Ú¾ÛŒÚº Ø®ÙˆØ´ÛŒ ØªÙˆ ÛŒÛ ÛÛ’ Ú©Û ÙˆÛ ØºÙ… Ø¨Ú¾ÛŒ Ù¾Ú¾Ù„ Ø±ÛØ§ ÛÛ’ Ù…ÛŒØ§Úº Ù„Ú©Ú¾Ø§ Ù†ØµÛŒØ±Ø” Ù†Û’ ÛØ± Ø±Ù†Ú¯ Ù…ÛŒÚº Ø³ÙÛŒØ¯ Ùˆ"""

example_3 = """Ø¨Ø¬Ø§ Ú©Û Ø¢Ù†Ú©Ú¾ Ù…ÛŒÚº Ù†ÛŒÙ†Ø¯ÙˆÚº Ú©Û’ Ø³Ù„Ø³Ù„Û’ Ø¨Ú¾ÛŒ Ù†ÛÛŒÚº Ø´Ú©Ø³Øª Ø®ÙˆØ§Ø¨ Ú©Û’ Ø§Ø¨ Ù…Ø¬Ú¾ Ù…ÛŒÚº Ø­ÙˆØµÙ„Û’ Ø¨Ú¾ÛŒ Ù†ÛÛŒÚº Ù†ÛÛŒÚº Ù†ÛÛŒÚº ÛŒÛ Ø®Ø¨Ø± Ø¯Ø´Ù…Ù†ÙˆÚº Ù†Û’ Ø¯ÛŒ ÛÙˆÚ¯ÛŒ ÙˆÛ Ø¢Ø¦Û’ Ø¢ Ú©Û’ Ú†Ù„Û’ Ø¨Ú¾ÛŒ Ú¯Ø¦Û’ Ù…Ù„Û’ Ø¨Ú¾ÛŒ Ù†ÛÛŒÚº ÛŒÛ Ú©ÙˆÙ† Ù„ÙˆÚ¯ Ø§Ù†Ø¯Ú¾ÛŒØ±ÙˆÚº Ú©ÛŒ Ø¨Ø§Øª Ú©Ø±ØªÛ’ ÛÛŒÚº Ø§Ø¨Ú¾ÛŒ ØªÙˆ Ú†Ø§Ù†Ø¯ ØªØ±ÛŒ ÛŒØ§Ø¯ Ú©Û’ ÚˆÚ¾Ù„Û’ Ø¨Ú¾ÛŒ Ù†ÛÛŒÚº Ø§Ø¨Ú¾ÛŒ Ø³Û’ Ù…ÛŒØ±Û’ Ø±ÙÙˆÚ¯Ø± Ú©Û’ ÛØ§ØªÚ¾ ØªÚ¾Ú©Ù†Û’ Ù„Ú¯Û’ Ø§Ø¨Ú¾ÛŒ ØªÙˆ Ú†Ø§Ú© Ù…Ø±Û’ Ø²Ø®Ù… Ú©Û’ Ø³Ù„Û’ Ø¨Ú¾ÛŒ Ù†ÛÛŒÚº Ø®ÙØ§ Ø§Ú¯Ø±Ú†Û ÛÙ…ÛŒØ´Û ÛÙˆØ¦Û’ Ù…Ú¯Ø± Ø§Ø¨ Ú©Û’ ÙˆÛ Ø¨Ø±ÛÙ…ÛŒ ÛÛ’ Ú©Û ÛÙ… Ø³Û’ Ø§Ù†ÛÛŒÚº Ú¯Ù„Û’ Ø¨Ú¾ÛŒ Ù†ÛÛŒÚº"""

example_4 = """Ø²Ø­Ø§Ù„ Ù…Ø³Ú©ÛŒÚº Ù…Ú©Ù† ØªØºØ§ÙÙ„ Ø¯ÙˆØ±Ø§Ø¦Û’ Ù†ÛŒÙ†Ø§Úº Ø¨Ù†Ø§Ø¦Û’ Ø¨ØªÛŒØ§Úº Ú©Û ØªØ§Ø¨ ÛØ¬Ø±Ø§Úº Ù†Ø¯Ø§Ø±Ù… Ø§Û’ Ø¬Ø§Úº Ù†Û Ù„ÛŒÛÙˆ Ú©Ø§ÛÛ’ Ù„Ú¯Ø§Ø¦Û’ Ú†Ú¾ØªÛŒØ§Úº Ø´Ø¨Ø§Ù† ÛØ¬Ø±Ø§Úº Ø¯Ø±Ø§Ø² Ú†ÙˆÚº Ø²Ù„Ù Ùˆ Ø±ÙˆØ² ÙˆØµÙ„Øª Ú†ÙˆÚº Ø¹Ù…Ø± Ú©ÙˆØªØ§Û Ø³Ú©Ú¾ÛŒ Ù¾ÛŒØ§ Ú©Ùˆ Ø¬Ùˆ Ù…ÛŒÚº Ù†Û Ø¯ÛŒÚ©Ú¾ÙˆÚº ØªÙˆ Ú©ÛŒØ³Û’ Ú©Ø§Ù¹ÙˆÚº Ø§Ù†Ø¯Ú¾ÛŒØ±ÛŒ Ø±ØªÛŒØ§Úº ÛŒÚ©Ø§ÛŒÚ© Ø§Ø² Ø¯Ù„ Ø¯Ùˆ Ú†Ø´Ù… Ø¬Ø§Ø¯Ùˆ Ø¨ØµØ¯ ÙØ±ÛŒØ¨Ù… Ø¨Û Ø¨Ø±Ø¯ ØªØ³Ú©ÛŒÚº Ú©Ø³Û’ Ù¾Ú‘ÛŒ ÛÛ’ Ø¬Ùˆ Ø¬Ø§ Ø³Ù†Ø§ÙˆÛ’ Ù¾ÛŒØ§Ø±Û’ Ù¾ÛŒ Ú©Ùˆ ÛÙ…Ø§Ø±ÛŒ Ø¨ØªÛŒØ§Úº Ú†ÙˆÚº Ø´Ù…Ø¹ Ø³ÙˆØ²Ø§Úº Ú†ÙˆÚº Ø°Ø±Û Ø­ÛŒØ±Ø§Úº Ø² Ù…ÛØ± Ø¢Úº Ù…Û Ø¨Ú¯Ø´ØªÙ… Ø¢Ø®Ø± Ù†Û Ù†ÛŒÙ†Ø¯ Ù†ÛŒÙ†Ø§Úº Ù†Û Ø§Ù†Ú¯ Ú†ÛŒÙ†Ø§Úº Ù†Û Ø¢Ù¾ Ø¢ÙˆÛ’ Ù†Û Ø¨Ú¾ÛŒØ¬Û’ Ù¾ØªÛŒØ§Úº Ø¨Ø­Ù‚ Ø¢Úº Ù…Û Ú©Û Ø±ÙˆØ² Ù…Ø­Ø´Ø± Ø¨Ø¯Ø§Ø¯ Ù…Ø§Ø±Ø§ ÙØ±ÛŒØ¨ Ø®Ø³Ø±ÙˆØ” Ø³Ù¾ÛŒØª Ù…Ù† Ú©Û’ Ø¯ÙˆØ±Ø§Ø¦Û’ Ø±Ø§Ú©Ú¾ÙˆÚº Ø¬Ùˆ Ø¬Ø§Ø¦Û’ Ù¾Ø§Ø¤Úº Ù¾ÛŒØ§ Ú©ÛŒ Ú©Ú¾ØªÛŒØ§Úº"""

example_5 = """Ú¯Ø± Ø®Ø§Ù…Ø´ÛŒ Ø³Û’ ÙØ§Ø¦Ø¯Û Ø§Ø®ÙØ§Ø¦Û’ Ø­Ø§Ù„ ÛÛ’ Ø®ÙˆØ´ ÛÙˆÚº Ú©Û Ù…ÛŒØ±ÛŒ Ø¨Ø§Øª Ø³Ù…Ø¬Ú¾Ù†ÛŒ Ù…Ø­Ø§Ù„ ÛÛ’ Ú©Ø³ Ú©Ùˆ Ø³Ù†Ø§Ø¤Úº Ø­Ø³Ø±Øª Ø§Ø¸ÛØ§Ø± Ú©Ø§ Ú¯Ù„Û Ø¯Ù„ ÙØ±Ø¯ Ø¬Ù…Ø¹ Ùˆ Ø®Ø±Ú† Ø²Ø¨Ø§Úº ÛØ§Ø¦Û’ Ù„Ø§Ù„ ÛÛ’ Ú©Ø³ Ù¾Ø±Ø¯Û Ù…ÛŒÚº ÛÛ’ Ø¢Ø¦Ù†Û Ù¾Ø±Ø¯Ø§Ø² Ø§Û’ Ø®Ø¯Ø§ Ø±Ø­Ù…Øª Ú©Û Ø¹Ø°Ø± Ø®ÙˆØ§Û Ù„Ø¨ Ø¨Û’ Ø³ÙˆØ§Ù„ ÛÛ’ ÛÛ’ ÛÛ’ Ø®Ø¯Ø§ Ù†Ø®ÙˆØ§Ø³ØªÛ ÙˆÛ Ø§ÙˆØ± Ø¯Ø´Ù…Ù†ÛŒ Ø§Û’ Ø´ÙˆÙ‚ Ù…Ù†ÙØ¹Ù„ ÛŒÛ ØªØ¬Ú¾Û’ Ú©ÛŒØ§ Ø®ÛŒØ§Ù„ ÛÛ’ Ù…Ø´Ú©ÛŒÚº Ù„Ø¨Ø§Ø³ Ú©Ø¹Ø¨Û Ø¹Ù„ÛŒ Ú©Û’ Ù‚Ø¯Ù… Ø³Û’ Ø¬Ø§Ù† Ù†Ø§Ù Ø²Ù…ÛŒÙ† ÛÛ’ Ù†Û Ú©Û Ù†Ø§Ù ØºØ²Ø§Ù„ ÛÛ’ ÙˆØ­Ø´Øª Ù¾Û Ù…ÛŒØ±ÛŒ Ø¹Ø±ØµÛ‚ Ø¢ÙØ§Ù‚ ØªÙ†Ú¯ ØªÚ¾Ø§ Ø¯Ø±ÛŒØ§ Ø²Ù…ÛŒÙ† Ú©Ùˆ Ø¹Ø±Ù‚ Ø§Ù†ÙØ¹Ø§Ù„ ÛÛ’ ÛØ³ØªÛŒ Ú©Û’ Ù…Øª ÙØ±ÛŒØ¨ Ù…ÛŒÚº Ø¢ Ø¬Ø§Ø¦ÛŒÙˆ Ø§Ø³Ø¯Ø” Ø¹Ø§Ù„Ù… ØªÙ…Ø§Ù… Ø­Ù„Ù‚Û‚ Ø¯Ø§Ù… Ø®ÛŒØ§Ù„ ÛÛ’ Ù¾ÛÙ„Ùˆ ØªÛÛŒ Ù†Û Ú©Ø± ØºÙ… Ùˆ Ø§Ù†Ø¯ÙˆÛ Ø³Û’ Ø§Ø³Ø¯Ø” Ø¯Ù„ ÙˆÙ‚Ù Ø¯Ø±Ø¯ Ú©Ø± Ú©Û ÙÙ‚ÛŒØ±ÙˆÚº Ú©Ø§ Ù…Ø§Ù„ ÛÛ’"""

# Create tabs for different app modes
tab1, tab2 = st.tabs(["ğŸ“œ Example Ghazals", "âœï¸ Custom Text"])

with tab1:
    st.markdown("### Select a ghazal to translate")
    
    # Organize example buttons into a grid of cards
    st.markdown('<div class="card-container">', unsafe_allow_html=True)
    
    # Example 1 card
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        st.markdown('<div class="example-btn-1">', unsafe_allow_html=True)
        if st.button("Ghazal 1"):
            st.session_state.selected_text = example_1
            st.session_state.current_tab = "tab1"
        st.markdown('</div>', unsafe_allow_html=True)
        
    with col2:
        st.markdown('<div class="example-btn-2">', unsafe_allow_html=True)
        if st.button("Ghazal 2"):
            st.session_state.selected_text = example_2
            st.session_state.current_tab = "tab1"
        st.markdown('</div>', unsafe_allow_html=True)
        
    with col3:
        st.markdown('<div class="example-btn-3">', unsafe_allow_html=True)
        if st.button("Ghazal 3"):
            st.session_state.selected_text = example_3
            st.session_state.current_tab = "tab1"
        st.markdown('</div>', unsafe_allow_html=True)
        
    with col4:
        st.markdown('<div class="example-btn-4">', unsafe_allow_html=True)
        if st.button("Ghazal 4"):
            st.session_state.selected_text = example_4
            st.session_state.current_tab = "tab1"
        st.markdown('</div>', unsafe_allow_html=True)
        
    with col5:
        st.markdown('<div class="example-btn-5">', unsafe_allow_html=True)
        if st.button("Ghazal 5"):
            st.session_state.selected_text = example_5
            st.session_state.current_tab = "tab1"
        st.markdown('</div>', unsafe_allow_html=True)
    
    st.markdown('</div>', unsafe_allow_html=True)

with tab2:
    st.markdown("### Enter your own Urdu text")
    
    # Text area for custom input
    custom_text = st.text_area(
        "Type or paste Urdu text here:", 
        height=150,
        key="custom_text_input",
        help="Enter Urdu text you'd like to translate to Roman Urdu"
    )
    
    if st.button("Translate Custom Text", key="translate_custom"):
        if custom_text:
            st.session_state.selected_text = custom_text
            st.session_state.current_tab = "tab2"
        else:
            st.warning("Please enter some Urdu text first.")

# Display selected text and translation
if "selected_text" in st.session_state:
    st.markdown("---")
    
    # Create columns for source and target
    col_source, col_target = st.columns(2)
    
    with col_source:
        st.markdown("### Original Urdu Text:")
        st.markdown(f"""
        <div style="background-color:#f8f9fa; padding:15px; border-radius:10px; border-left:5px solid #5c6bc0; 
                     direction:rtl; text-align:right; font-family:'Jameel Noori Nastaleeq', Arial, sans-serif; font-size:18px;">
            {st.session_state.selected_text}
        </div>
        """, unsafe_allow_html=True)
    
    # Load model if not already loaded
    if "model_loaded" not in st.session_state:
        with st.spinner("Loading translation model..."):
            model, urdu_vocab_map, roman_vocab_map, urdu_merges = load_model()
            if model:
                st.session_state.model = model
                st.session_state.urdu_vocab_map = urdu_vocab_map
                st.session_state.roman_vocab_map = roman_vocab_map
                st.session_state.urdu_merges = urdu_merges
                st.session_state.model_loaded = True
    
    # Translate and display
    with col_target:
        st.markdown("### Roman Urdu Translation:")
        
        if "model_loaded" in st.session_state:
            # Check if we've already translated this text
            cache_key = f"trans_{st.session_state.selected_text[:20]}"
            if cache_key not in st.session_state:
                with st.spinner("Translating..."):
                    translation = translate_text(
                        st.session_state.selected_text,
                        st.session_state.model,
                        st.session_state.urdu_merges,
                        st.session_state.urdu_vocab_map,
                        st.session_state.roman_vocab_map
                    )
                    st.session_state[cache_key] = translation
            else:
                translation = st.session_state[cache_key]
            
            # Display translation in styled box
            st.markdown(f"""
            <div style="background-color:#f8f9fa; padding:15px; border-radius:10px; border-left:5px solid #26a69a; 
                      font-family:Arial, sans-serif; font-size:16px;">
                {translation}
            </div>
            """, unsafe_allow_html=True)
        else:
            st.error("Error: Could not load the translation model.")

    # Add model information section
    with st.expander("About the Translation Model"):
        st.markdown("""
        ### Model Architecture
        This translator uses a Sequence-to-Sequence model with attention mechanism:
        
        - **Encoder**: Bidirectional LSTM with 1 layer
        - **Decoder**: LSTM with 2 layers and Bahdanau attention
        - **Embeddings**: 128-dimensional for both languages
        - **Tokenization**: Specialized BPE with word boundary markers for Urdu
        
        ### Limitations
        The current model has several limitations:
        - Limited vocabulary coverage
        - May struggle with complex poetic expressions
        - Translation quality varies depending on input complexity
        """)

# Add footer with project information
st.markdown("""
<div class="footer">
    <p>Urdu to Roman Urdu Neural Machine Translation | Developed by Zeeshan Khalid & Zahid Iqbal</p>
    <p>MS Data Science Project | Instructor: Dr. Muhammad Usama</p>
</div>
""", unsafe_allow_html=True)
